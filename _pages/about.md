---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from:
  - /about/
  - /about.html
---

主に Vision & Language に興味があります。最近は特に motion の研究をしています。

## Biography

- 2023.10-Current: LINE ヤフー Virtual Human Lab 所属
- 2022.4-2023.9: LINE 株式会社 Computer Vision Lab 所属
- 2020.4-2022.3: 東京大学 大学院情報理工学系研究科 知能機械情報学専攻 博士課程 中途退学
- 2018.4-2020.3: 東京大学 大学院情報理工学系研究科 知能機械情報学専攻 修士課程 修了
- 2014.4-2018.3: 東京大学 工学部 機械情報工学科 卒業

## Publications

- <b>Role-aware Interaction Generation from Textual Description</b>,<br><u>Mikihiro Tanaka</u>, Kent Fujiwara<br>ICCV 2023 <b>Oral</b> (Acceptance rate: 1.8%) <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Tanaka_Role-Aware_Interaction_Generation_from_Textual_Description_ICCV_2023_paper.pdf" style="text-decoration:none">[Paper]</a> <a href="https://openaccess.thecvf.com/content/ICCV2023/supplemental/Tanaka_Role-Aware_Interaction_Generation_ICCV_2023_supplemental.pdf" style="text-decoration:none">[Sup]</a>
- <b>Generating Easy-to-Understand Referring Expressions for Target Identifications</b>,<br><u>Mikihiro Tanaka</u>, Takayuki Itamochi, Kenichi Narioka, Ikuro Sato, Yoshitaka Ushiku, Tatsuya Harada<br>ICCV 2019 <a href="https://arxiv.org/abs/1811.12104" style="text-decoration:none">[Paper]</a>

## Competitions

- <b>The 5th place in the task: Visual Question Answering (VQA) in CVPR2018.</b> <u>Mikihiro Tanaka</u>, Atsuhiro Noguchi, Kohei Uehara, Lisa Kawai, Yoshitaka Ushiku, Tatsuya Harada. <a href="https://visualqa.org/challenge_2018.html" style="text-decoration:none">[link]</a>

## Invited Talks

- <u>Mikihiro Tanaka</u>, Takayuki Itamochi, Kenichi Narioka, Ikuro Sato, Yoshitaka Ushiku, Tatsuya Harada. Generating Easy-to-Understand Referring Expressions for Target Identifications. <b>FIT</b>, 2020 <a href="https://www.ipsj.or.jp/event/fit/fit2020/" style="text-decoration:none">[link]</a>
- <u>Mikihiro Tanaka</u>, Takayuki Itamochi, Kenichi Narioka, Ikuro Sato, Yoshitaka Ushiku, Tatsuya Harada. Generating Easy-to-Understand Referring Expressions for Target Identifications. <b>PRMU</b>, 2019 <a href="https://www.ieice.org/ken/program/index.php?tgs_regid=9c4b1e7a01870119429e03e5996c8b7205108719ec69e7e644185c0e8fe30ac7&tgid=IEICE-PRMU" style="text-decoration:none">[link]</a>

## 依頼解説

- <u>Mikihiro Tanaka</u>, Takayuki Itamochi, Kenichi Narioka, Ikuro Sato, Yoshitaka Ushiku, Tatsuya Harada. Generating Easy-to-Understand Referring Expressions for Target Identifications. Journal of the Imaging Society of Japan (日本画像学会誌), 2020, 59.6: 591-600. <a href="https://www.jstage.jst.go.jp/article/isj/59/6/59_591/_article/-char/ja" style="text-decoration:none">[link]</a>

## メディア

- LINEヤフーが人体CG向け生成AI技術、役割を指定して2人の相互動作を出力<br>2023.11.10 日経Robotics <a href="https://xtech.nikkei.com/atcl/nxt/mag/rob/18/012600001/00134/" style="text-decoration:none">[link]</a>

## Reviewer

- ICCV2021

## Grants & Fellowships

- 2021.4 - 2021.9: 日本学術振興会 特別研究員（DC2)

---

last update: 2023/11/14
