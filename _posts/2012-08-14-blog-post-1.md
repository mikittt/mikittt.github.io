---
title: '高精度な日本語マルチモーダル大規模言語モデルの構築にむけたデータセットの検討 (NLP2025)'
permalink: /posts/Japanese_MLLM
---

田中 幹大,　朱 佩菲,　横尾 修平 (LINEヤフー株式会社)

- [概要](#概要)
- [実験結果](#実験結果)
- [RecruitQAベンチマークの作成](#RecruitQAベンチマークの作成)


<a id='概要'>概要</a>
------
近年、大規模言語モデル　(LLM) に視覚情報を統合した、マルチモーダル大規模言語モデル（MLLM）が注目を集めており、その応用範囲は急速に拡大している。しかし、日本ドメインに特化したMLLM を作る上で、英語のデータに比べて公開データが少ない課題がある。本研究では、高精度な日本語MLLMを構築するためのデータセットの作成方法について検討し、実験を行った。構築したモデルは、日本ドメインの画像理解を問うベンチマークにおいて、他のモデルよりも優位な結果を示し、その有効性を実証した。

<a id='実験結果'>実験結果</a>
------
日本ドメインの画像を扱う、Heron-BenchとJA-VLM-Benchにおいて既存手法を上回る性能を達成した。
<img src='/images/japanese_mllm/quantitative.png'>

本研究では[CALM3-22B](https://huggingface.co/cyberagent/calm3-22b-chat)を用いてMLLMを構築した。本研究で構築したデータセットの有用性を確認するために、VILA-jpと同様[llm-jp-3-13b-instruct](https://huggingface.co/llm-jp/llm-jp-3-13b-instruct)を用いた実験を行った。

実験により、llm-jp-3-13b-instructではCALM3よりもデータのノイズによる影響を受けやすく、適切なfilteringを行うことでVILA-jpを上回る性能を得た(表下から2番目)。ここで、filteringは作成したデータの中で、解答文に疑問文を含むものを除く処理を行った。

| Models                     | Heron-Bench <br> LLM Average (%) | JA-VLM-Bench <br> LLM (/5.0) |
|----------------------------|----------------------------------|------------------------------|
| VILA-jp (SigLIP+llm-jp)    | 57.2       | 3.69|
| 提案 (SigLIP+llm-jp)       | 56.6       | 3.62|
| 提案 w/ filtering (SigLIP+llm-jp)       | 60.4       | 3.7|
| 提案 (SigLIP+CALM3)        | 63.3       | 3.82|

定性的結果例を以下に示す。
<img src='/images/japanese_mllm/qualitative.png'>


<a id='RecruitQAベンチマークの作成'>RecruitQAベンチマークの作成</a>
------

これまで、日本ドメイン画像を用いて、Heron-BenchやJA-VLM-Benchに加えて、JMMMUといったベンチマークが提案されてきた。しかし、これまでの日本語MLLMの評価ベンチマークでは、評価件数とタスク設計において、シンプルな日本ドメインの画像の認識能力を測る上で課題があった。
まず、評価件数についてHeron-BenchやJA-VLM-Benchは質問の件数が100件程度と少なく、評価結果にブレが生じやすい課題がある。
一方でJMMMUでは件数は多いが、LLMの知識を問う複雑な質問からなるため、シンプルな画像理解の能力は測れない課題がある。

そこで、Recruit社が日本語CLIPの評価のために公開した[データセット](https://huggingface.co/datasets/recruit-jp/japanese-image-classification-evaluation-dataset)を用いて4択式の7,654件の質問を付与した、RecruitQAと呼ぶベンチマークによる評価を提案する。4つの選択肢のうち誤りの回答は、正解と最も類似しているクラスをクラス名の候補からLLMによって選択して用意した。

提案するRecruitQAベンチマークは、元のデータセットと同じで、jaflower30(日本の花30種)・jafood101(日本の食材、料理101種)・
jalandmark10(日本のランドマーク10種)・jafacility20(日本の施設20種)から構成される。

ベンチマークの例を以下に示す。
<img src='/images/japanese_mllm/RecruitQA.png'>

他の日本ドメインのベンチマークとの比較は以下のようになっている。

| ベンチマーク                     | 質問数 | 評価方法 | 
|-------------|---------------|----------------|
|[Heron-Bench](https://huggingface.co/datasets/turing-motors/Japanese-Heron-Bench) | 102 | LLM |
|[JA-VLM-Bench](https://huggingface.co/datasets/SakanaAI/JA-VLM-Bench-In-the-Wild) | 60| LLM |
|[JMMMU](https://huggingface.co/datasets/JMMMU/JMMMU) | 1320| 正解率 |
| RecruitQA (提案) | 7654| 正解率 |



評価結果は以下のようになった。CLYPとは、弊社内で開発している日本ドメインに特化したCLIPであり、MLLMの画像エンコーダーとしてCLYPを用いた方が海外ドメインで主に訓練されているSigLIPを用いた時よりも性能が高くなった。

| 画像エンコーダー                     | jaflower30|jafood101|jalandmark10|jafacility20|平均|
|-------------|---------------|----------------|------------------|----------------|--------------|
|SigLIP | 0.92 |0.84|0.79|0.86|0.85|
|CLYP | 0.95|0.91|0.89|0.93|0.92|