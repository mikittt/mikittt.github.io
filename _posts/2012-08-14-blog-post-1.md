---
title: '高精度な日本語マルチモーダル大規模言語モデルの構築にむけたデータセットの検討 (NLP2025)'
permalink: /posts/Japanese_MLLM
---

田中 幹大, 朱 佩菲, 横尾 修平 (LINEヤフー株式会社) [[paper]](https://github.com/mikittt/mikittt.github.io/tree/master/_posts/files/jmllm.pdf)

このページでは、NLPの論文内容に加え、新しく日本語MLLMのベンチマークとして提案するJIC-QAベンチマークについても紹介する。

- [概要](#概要)
- [実験結果](#実験結果)
- [JIC-QAベンチマークの作成](#JIC-QAベンチマークの作成)


<a id='概要'>概要</a>
------
近年、大規模言語モデル　(LLM) に視覚情報を統合した、マルチモーダル大規模言語モデル（MLLM）が注目を集めており、その応用範囲は急速に拡大している。しかし、日本ドメインに特化したMLLM を作る上で、英語のデータに比べて公開データが少ない課題がある。本研究では、高精度な日本語MLLMを構築するためのデータセットの作成方法について検討し、実験を行った。構築したモデルは、日本ドメインの画像理解を問うベンチマークにおいて、他のモデルよりも優位な結果を示し、その有効性を実証した。

<a id='実験結果'>実験結果</a>
------
提案モデルは、日本ドメインの画像を扱うHeron-BenchとJA-VLM-Benchにおいて既存手法を上回る性能を達成した。
<img src='/images/japanese_mllm/quantitative.png'>

本研究では[CALM3-22B](https://huggingface.co/cyberagent/calm3-22b-chat)を用いてMLLMを構築した。本研究で構築したデータセットの有用性を確認するために、VILA-jpと同様[llm-jp-3-13b-instruct](https://huggingface.co/llm-jp/llm-jp-3-13b-instruct)を用いた実験を行った。

実験により、提案データセットに対して                                                  適切なfilteringを行うことでVILA-jpを上回る性能を得た(表下から2番目)。ここで、filteringは作成したデータの中で、解答文に疑問文を含むものを除く処理を行った。また、llm-jp-3-13b-instructよりも大きなCALM3-22Bがこれらのベンチマークでも有効であることが分かった。

| Models       |     LLM         | Heron-Bench <br> LLM Average (%) | JA-VLM-Bench <br> LLM (/5.0) |
|--------------|--------------|----------------------------------|------------------------------|
| VILA-jp  | llm-jp-3-13b-instruct         | 57.2       | 3.69|
| 提案      | llm-jp-3-13b-instruct         | 56.6       | 3.62|
| 提案 w/ filtering | llm-jp-3-13b-instruct | 60.4       | 3.7|
| 提案      | CALM3-22B        | 63.3       | 3.82|

定性的結果例を以下に示す。
<img src='/images/japanese_mllm/qualitative.png'>


<a id='JIC-QAベンチマークの作成'>JIC-QAベンチマークの作成</a>
------

これまで、日本ドメイン画像を用いて、Heron-BenchやJA-VLM-Benchに加えて、JMMMUといった日本語MLLMのベンチマークが提案されてきた。しかし、これらの日本語MLLMの評価ベンチマークでは、シンプルな日本ドメインの画像の認識能力を測る上で以下のような課題があった。
- Heron-BenchやJA-VLM-Benchは質問の件数が100件程度と少なく、評価結果にブレが生じやすい課題がある。
- JMMMUは件数は多いが、LLMの知識も問う複雑な質問からなるため、画像内の物体名の理解などのシンプルな能力は測れない課題がある。

そこで、Recruit社が日本語CLIPの評価のために公開した[japanese-image-classification-evaluation-dataset](https://huggingface.co/datasets/recruit-jp/japanese-image-classification-evaluation-dataset)を用いて4択式の7,654件の質問を付与した、Japanese-Image-Classification-QA(JIC-QA)と呼ぶベンチマークによる評価を提案する。4つの選択肢のうち誤りの回答は、正解と最も類似しているクラスをクラス名の候補からLLMによって選択して用意した。

提案するJIC-QAベンチマークは、元のデータセットと同じで、jaflower30(日本の花30種)・jafood101(日本の食材、料理101種)・
jalandmark10(日本のランドマーク10種)・jafacility20(日本の施設20種)から構成される。

ベンチマークの例を以下に示す。
<img src='/images/japanese_mllm/JIC-QA.png'>

他の日本ドメインのベンチマークとの比較を以下の表に示す。提案するJIC-QAは日本ドメインの画像の常識的なレベルの理解を問う、大きなベンチマークとなっている。

| ベンチマーク                     | 質問数 | レベル | 評価方法 | 
|-------------|---------------|----------------|
|[Heron-Bench](https://huggingface.co/datasets/turing-motors/Japanese-Heron-Bench) | 102 | 常識 | LLM |
|[JA-VLM-Bench](https://huggingface.co/datasets/SakanaAI/JA-VLM-Bench-In-the-Wild) | 60| 常識 | LLM |
|[JMMMU](https://huggingface.co/datasets/JMMMU/JMMMU) | 1,320| 専門的 | 正解率 |
| JIC-QA (提案) | 7,654| 常識 | 正解率 |



評価結果を以下の表に示す。CLYP(ViT-L/14@336px)とは、日本ドメインに特化したCLIPである[clip-japanese-base](https://huggingface.co/line-corporation/clip-japanese-base)のモデルサイズや解像度を大きくしたバージョンである。MLLMの画像エンコーダーとしてCLYPを用いた方が海外ドメインで主に訓練されているSigLIPを用いた時よりも性能が高くなり、特にランドマークの認識で大きな差がついた。

| 画像エンコーダー      | jaflower30|jafood101|jalandmark10|jafacility20|平均|
|-------------|---------------|----------------|------------------|----------------|--------------|
|提案モデル w/ SigLIP               | 0.92|0.84|0.79|0.86|0.85|
|提案モデル w/ CLYP(ViT-L/14@336px) | 0.95|0.91|0.89|0.93|0.92|

定性的な結果を以下の図に示す。これらの結果からも、海外ドメインで学習された画像エンコーダーを用いると、豊富な日本ドメインの知識を持つLLMと合わせたMLLMを学習しても日本ドメインの画像理解に課題を残すことがわかり、日本ドメインにおいて強力な画像エンコーダーの構築が重要であることが分かる。

<img src='/images/japanese_mllm/new-res2.png' width="70%">