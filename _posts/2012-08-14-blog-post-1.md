---
title: '高精度な日本語マルチモーダル大規模言語モデルの構築にむけたデータセットの検討 (NLP2025)'
permalink: /posts/Japanese_MLLM
---

田中 幹大,　朱 佩菲,　横尾 修平



概要
------
近年，大規模言語モデル(LLM) に視覚情報を統合した，マルチモーダル大規模言語モデル（MLLM）が注目を集めており，その応用範囲は急速に拡大している．しかし，日本ドメインに特化したMLLM を作る上で，英語のデータに比べて公開データが少ない課題がある．本研究では，高精度な日本語MLLMを構築するためのデータセットの作成方法について検討し，実験を行った．構築したモデルは，日本ドメインの画像理解を問うベンチマークにおいて，他のモデルよりも優位な結果を示し，その有効性を実証した．

定量的結果
------
日本ドメインの画像を扱う、
<img src='/images/japanese_mllm/quantitative.png'>

本研究では[CALM3-22B](https://huggingface.co/cyberagent/calm3-22b-chat)を用いてMLLMを構築した。本研究で構築したデータセットの有用性を確認するために、VILA-jpと同様[llm-jp-3-13b-instruct](https://huggingface.co/llm-jp/llm-jp-3-13b-instruct)を用いた実験を行った。

実験により、llm-jp-3-13b-instructではCALM3よりもデータのノイズによる影響を受けやすく、適切なfilteringを行うことでVILA-jpを上回る性能を得た(表下から2番目)。ここで、filteringは作成したデータの中で、解答文に疑問文を含むものを除く処理を行った。

| Models                     | Heron-Bench <br> LLM Average (%) | JA-VLM-Bench <br> LLM (/5.0) |
|----------------------------|----------------------------------|------------------------------|
| VILA-jp (SigLIP+llm-jp)    | 57.2       | 3.69|
| 提案 (SigLIP+llm-jp)       | 56.6       | 3.62|
| 提案 w/ filtering (SigLIP+llm-jp)       | 60.4       | 3.7|
| 提案 (SigLIP+CALM3)        | 63.3       | 3.82|

定性的結果
------
<img src='/images/japanese_mllm/qualitative.png'>

JMMMUベンチマークによる評価
------

ベンチマークの作成
------